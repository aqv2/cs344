{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 1 of Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the probabilities are . . .\n",
      "I = 0.99\n",
      "spam = 0.99\n",
      "am = 0.99\n",
      "like = 0.5\n",
      "not = 0.5\n",
      "do = 0.5\n",
      "spamiam = 0.5\n",
      "that = 0.5\n",
      "i = 0.01\n",
      "green = 0.01\n",
      "ham = 0.01\n",
      "eggs = 0.01\n",
      "and = 0.01\n"
     ]
    }
   ],
   "source": [
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "# This table will contain our probability table\n",
    "is_it_ham_or_spam = {}\n",
    "\n",
    "# This builds the words from the spam corpus into a dict of words and the number of times which they occur\n",
    "spam_table = {}\n",
    "for spam in spam_corpus:\n",
    "    for spam_word in spam:\n",
    "        if spam_word not in spam_table:\n",
    "            spam_table[spam_word] = 1\n",
    "            # Adding the word to our probability table\n",
    "            is_it_ham_or_spam[spam_word] = None\n",
    "        else:\n",
    "            spam_table[spam_word] += 1\n",
    "            \n",
    "            \n",
    "# This builds the words from the ham corpus into a dict of words and the number of times they occur.\n",
    "ham_table = {}\n",
    "for ham in ham_corpus:\n",
    "    for ham_word in ham:\n",
    "        if ham_word not in ham_table:\n",
    "            ham_table[ham_word] = 1\n",
    "            # Adding the word to our probability table\n",
    "            is_it_ham_or_spam[ham_word] = None\n",
    "        else:\n",
    "            ham_table[ham_word] += 1\n",
    "            \n",
    "# Setting up to use the variable names he uses in his algorithm, for easier, less error-prone coding on my part\n",
    "ngood = len(ham_corpus)\n",
    "nbad = len(spam_corpus)\n",
    "\n",
    "# Building our probability list\n",
    "for token in is_it_ham_or_spam:\n",
    "    if token in ham_table.keys():\n",
    "        g = 2 * ham_table[token]\n",
    "    else:\n",
    "        g = 0\n",
    "    \n",
    "    if token in spam_table.keys():\n",
    "        b = spam_table[token]\n",
    "    else:\n",
    "        b = 0\n",
    "        \n",
    "    if not ((g + b) < 1):\n",
    "        is_it_ham_or_spam[token] = max(.01, min(.99, min(1, b/nbad), min(1, g/ngood) + min(1, b/nbad)))\n",
    "\n",
    "print(\"And the probabilities are . . .\")\n",
    "for token in sorted(is_it_ham_or_spam, key=is_it_ham_or_spam.get, reverse=True):\n",
    "    print(token, \"=\", is_it_ham_or_spam[token])\n",
    "\n",
    "# This is a Bayesian approach to SPAM because each of the probabilities it builds is the probability that a given\n",
    "# email is spam, given that it has a given word from either corpus in it. And the conditional probability in uses\n",
    "# like that is calculated with Bayes' Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 of Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.5, True: 0.5\n",
      "False: 0.9, True: 0.1\n",
      "False: 0.952, True: 0.0476\n",
      "False: 0.01, True: 0.99\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# Part a: the implementation\n",
    "# From AIMA code (probability.py) - Fig. 14.2 - burglary example\n",
    "wetGrass = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.10, F: 0.50}),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.00})\n",
    "    ])\n",
    "\n",
    "#Part b: the quantity of independent values assuming nothing\n",
    "\n",
    "#Part c: the quantity of independent values assuming the Bayes network\n",
    "\n",
    "\n",
    "# Part d(1): the derivation by computer\n",
    "# d.i This value may be taken directly from the graph\n",
    "print(elimination_ask('Cloudy', dict(), wetGrass).show_approx())\n",
    "\n",
    "# d.ii \n",
    "print(elimination_ask('Sprinkler', dict(Cloudy=T), wetGrass).show_approx())\n",
    "\n",
    "# d.iii\n",
    "print(elimination_ask('Cloudy', dict(Sprinkler=T, Rain=F), wetGrass).show_approx())\n",
    "\n",
    "# d.iii\n",
    "print(elimination_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), wetGrass).show_approx())\n",
    "\n",
    "# d.iii\n",
    "print(elimination_ask('Cloudy', dict(WetGrass=F), wetGrass).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part d(2): the derivation by hand: See handwritten work turned into your office"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
