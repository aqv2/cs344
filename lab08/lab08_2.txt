a)
The FTRL uses the specified rate as a baseline, and creates a learning rate gradient out of it.

b)
Sorting data into buckets helps categorize it and allow for easier interpretation of it. You may not need to know exactly
the income of an area, but if you can categorize it with relation to other areas, you get almost as much information out of it.
In other words, bucketing allows you to simplify information when what you care about is how that information compares to
other information in the same area.

c)
Task 1:
  #
  # YOUR CODE HERE: bucketize the following columns, following the example above:
  #
  bucketized_latitude = tf.feature_column.bucketized_column(
    latitude, boundaries=get_quantile_based_boundaries(
      training_examples["latitude"], 10))

  bucketized_housing_median_age = tf.feature_column.bucketized_column(
    housing_median_age, boundaries=get_quantile_based_boundaries(
      training_examples["housing_median_age"], 7))

  bucketized_median_income = tf.feature_column.bucketized_column(
    median_income, boundaries=get_quantile_based_boundaries(
      training_examples["median_income"], 7))

  bucketized_rooms_per_person = tf.feature_column.bucketized_column(
    rooms_per_person, boundaries=get_quantile_based_boundaries(
      training_examples["rooms_per_person"], 7))

This did make overall sense to me, but, it is a little unclear to me how they arrived at the exact number of buckets
that they did for each feature.

Task 2:
long_x_lat = tf.feature_column.crossed_column(
set([bucketized_longitude, bucketized_latitude]), hash_bucket_size=1000)
N.B. It is unclear to me why the hash_bucket_size parameter is necessary/what it does, exactly. And the docs on it are
not helpful

An interesting cross to look at would be to look at total_rooms X households. This could give you a sense of how densely
built up and populated a block is, and a sense of the average size of the households on that block would be (i.e. if
there are a bunch of mansions in a given area, then total_rooms X households would be lower).