{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Preliminary Note: Recall that I cannot use any specifically markdown formatting in the notebook, since opening it in PyCharm (a necessary operation to ensure it has saved appropriately) will delete any cell with special markdown formatting.\n",
    "\n",
    "Vision Revision:\n",
    "For my final project, I propose to build a neural network trained to generate poetry in the style of John  Milton. My dataset will be a simple text file containing the entirety of Paradise Lost.\n",
    "\n",
    "Background:\n",
    "This project will use an LSTM (Long short-term memory) trained on the text of Paradise Lost. An LSTM is a specific type of recurrent neural network (RNN) which is structured specifically to be able to learn longer term interdependencies between inputs. This LSTM will analyze the text of Paradise Lost tokenized by letter, and will generate output coorespondingly. My model for this will be Chollet (https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.1-text-generation-with-lstm.ipynb) with some cross-referencing of another example (https://github.com/pranjal52/text_generators) which was unfortunately running too slow to be very useful.\n",
    "\n",
    "Implementation:\n",
    "My implementation is not significantly different from Chollet's at this point. Once it is, I will have more to say on this matter.\n",
    "\n",
    "Results:\n",
    "Again, since my implementation is about the same as Chollet's currently, I do not have final results yet. That being said, these preliminary results are very promising, I think, and there is only room for improvement from here with finetuning Chollet's model.\n",
    "\n",
    "Implications:\n",
    "Poetry is weird. A conglomeration of semi-coherent, half-connected words and phrases whose structure and interplay somehow amount to far more than their mere parts -- it does not seem like the sort of thing that a NN or AI (at least currently) could convincingly fake. It's too human, too subjective. But the fact that it is subjective and often so open to interpretation is exactly what makes the potential for NN-generated poetry so great. If someone doesn't know that a poem has been generated by an un-thinking AI (and no AI that I am aware of can currently be described as thinking, in a human sense), they will impute their own interpretations and understandings into the poem and attribute them to the author. If a NN can generate convingingly human poetry, it is due in large part to how nebulous and varying poetry is in the first place. But that fact is simultaneously why it would be difficult to train a NN to generate convincing poetry. The variation and inconsistency that makes poetry such a uniquely human affair also makes it difficult to train a NN on. This is one of the reasons why I have trouble believing any AI will ever be up to or exceed the capacity of a human beings in their own domains (obviously computers can easily surpass human beings at, say, raw computational power and things of that sort). There is something about us that makes us and our cultural activities distinct from mere mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 454206\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "text = open(\"projectData.txt\").read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 151382\n",
      "Unique characters: 39\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aqv2/Desktop/cs344-masterfolder/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "151382/151382 [==============================] - 63s 415us/step - loss: 1.4332\n",
      "--- Generating with seed: \"m just and right,\n",
      "sufficient to have stood, though free to f\"\n",
      "------ temperature: 0.2\n",
      "m just and right,\n",
      "sufficient to have stood, though free to fair\n",
      "of sense, and with man thou satan sent the sense\n",
      "and for the sate to the sent and stand\n",
      "soul the sentent shall to the death and starr\n",
      "of this sent of his seems, and the sent\n",
      "the sentent from the sent the seeds of god,\n",
      "and for the sentent returnd, and the pain,\n",
      "and the sentence the sent the seat and armes,\n",
      "and with sense, and seems the sent the servite\n",
      "the sentent the sees the sent the sent\n",
      "the\n",
      "------ temperature: 0.5\n",
      " sent the servite\n",
      "the sentent the sees the sent the sent\n",
      "the self with flight host above here saw,\n",
      "and meet as that selfonce in pains to black from heav'n\n",
      "and winders thir paine, and to stood beasts\n",
      "the pain, and dreadful servites the windes.\n",
      "thou seem from heav'ns this sea and new to assare\n",
      "in heav'n thou in the first the death compation,\n",
      "and the sense, and saw and good or nighting spake,\n",
      "the sentent chance to subpine to be shon\n",
      "on this through the wings \n",
      "------ temperature: 1.0\n",
      "tent chance to subpine to be shon\n",
      "on this through the wings and creaturel, spake\n",
      "hand without natures th' more shall me not,\n",
      "but how mad'd hee felld manst and herh,\n",
      "either prieible; as where his mowisince soon we both\n",
      "offojto aire more: thy po thus adam heard,\n",
      "yet from servite, the busidess, and here oine\n",
      "with his waters, and from his tree his taste\n",
      "soundest arme, and sown, and singrsid thee enterd,\n",
      "i thus semn, to those rais'd by open with hills.\n",
      " say: as\n",
      "------ temperature: 1.2\n",
      "d,\n",
      "i thus semn, to those rais'd by open with hills.\n",
      " say: as in doupt in thou, and infernal vain\n",
      "world dreadful exberg'd of mongents raught i bestiond\n",
      "that senseral ta day freely acclame,\n",
      "to mee small bewial, or doge; and'd oure surcuruce\n",
      "lakes, of arsffore somlest, and crite to gath\n",
      "mrasist, bound for lagrous rebell winns say,\n",
      "commandst procelow, unon th' angeskind\n",
      "amarr'd acnapstols of thy place.\n",
      "thy seoive, satan 'derestaatabes had\n",
      "with windancent enfac\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 5 epochs on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=3)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
