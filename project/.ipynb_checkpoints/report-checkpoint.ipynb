{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Preliminary Note: Recall that I cannot use any specifically markdown formatting in the notebook, since opening it in PyCharm (a necessary operation to ensure it has saved code appropriately) will permanently delete any cell with special markdown formatting.\n",
    "\n",
    "Vision Revision:\n",
    "For my final project, I propose to build a neural network trained to generate poetry in the style of John  Milton. My dataset will be a simple text file containing the entirety of Paradise Lost (about 11,000 lines of unrhyming iambic pentameter (also known as blank verse)).\n",
    "\n",
    "Background:\n",
    "This project will use an LSTM (Long short-term memory) trained on the text of Paradise Lost. An LSTM is a specific type of recurrent neural network (RNN) which is structured in order to be able to learn longer term interdependencies between inputs. This LSTM will analyze the text of Paradise Lost, tokenized by letter, and will generate output coorespondingly. My model for this will be Chollet (https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.1-text-generation-with-lstm.ipynb) with some cross-referencing of another example (https://github.com/pranjal52/text_generators) which was unfortunately running too slow on the lab computers to be very useful, but did provide some structural guidance.\n",
    "\n",
    "Implementation:\n",
    "My implementation is not significantly different from Chollet's at this point. Once it is, I will have more to say on this matter.\n",
    "\n",
    "Results:\n",
    "Again, since my implementation is about the same as Chollet's currently, I do not have final results yet. That being said, these preliminary results are very promising, I think, and there is only room for improvement from here with finetuning Chollet's model.\n",
    "\n",
    "Implications:\n",
    "Poetry is weird. A conglomeration of semi-coherent, half-connected words and phrases whose structure and interplay somehow amount to far more than their mere parts -- it does not seem like the sort of thing that a NN or AI (at least currently) could convincingly fake. It's too human, too subjective, and toes the line between nonsense and beauty far too closely. But the fact that it is subjective and often so open to interpretation is exactly what makes the potential for NN-generated poetry so great. If someone doesn't know that a poem has been generated by an un-thinking AI (and no AI that I am aware of can currently be described as thinking, in a human sense), they will impute their own interpretations and understandings into the poem and attribute them to the author. In other words, if a neural network can generate convingingly human poetry, it is due in large part to how nebulous and varying poetry is in the first place. But that fact is simultaneously why it would be difficult to train a neural network to generate convincing poetry. The variation and inconsistency that makes poetry such a uniquely human affair also makes it difficult to train a neural network on. This is one of the reasons why I have trouble believing any AI will ever be up to or exceed the capacity of a human beings in their own domains (obviously computers can easily surpass human beings at, say, raw computational power and things of that sort). There is something about us that makes us and our cultural activities distinct from, and greater than, mere mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 454312\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "text = open(\"projectData.txt\").read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 151418\n",
      "Unique characters: 38\n",
      "['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "print(chars)\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aqv2/Desktop/cs344-masterfolder/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "WARNING:tensorflow:From /home/aqv2/Desktop/cs344-masterfolder/venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "151418/151418 [==============================] - 67s 444us/step - loss: 2.0031\n",
      "--- Generating with seed: \"the miserie, i deserv'd it, and would beare\n",
      "my own deserving\"\n",
      "------ temperature: 0.2\n",
      "the miserie, i deserv'd it, and would beare\n",
      "my own deserving the son the serve the senfer the heav'n,\n",
      "the subfer the subfirit all the sunger forme\n",
      "of the his serve he see the earth the here the senf\n",
      "or son the subthe subfirits the saw\n",
      "of death the serve all the heav'n,\n",
      "and sadd the senfer the heav'nly son the senf\n",
      "to heav'nly the more his more he here see her son\n",
      "the serve to heav'nly strows\n",
      "of the serve the ender the serve the subfarring the subfeer\n",
      "of th\n",
      "------ temperature: 0.5\n",
      "e serve the ender the serve the subfarring the subfeer\n",
      "of the fair in man of the brist of the barths\n",
      "created to and endem sorning the side, sill\n",
      "of dainion proend the sorn\n",
      "of serve all who the sore the subt nor mound\n",
      "stound the spirite in thir forde to subdere the senf\n",
      "cast aither the eastion son that son her subfarr and morn\n",
      "to end then him soff receave that might\n",
      "the plarating thir song first his sorn\n",
      "sere the him ender the manser all the easter, soon,\n",
      "o\n",
      "------ temperature: 1.0\n",
      "s sorn\n",
      "sere the him ender the manser all the easter, soon,\n",
      "one to mond hundering to drrotsh'd,\n",
      "dishind give onk, remiciour i apsake,\n",
      "trusts what sload, and pield\n",
      "com\n",
      "sadange \n",
      "oo stromying falst butker sanfum'd\n",
      "be the gads, his deep; rowen lape, il mourhing outten cate\n",
      "iulf, wor the eake our long lestom will rime\n",
      "on all rournd gand fiowridaitistaris'd\n",
      "nofetence as hast xattaring ray the hate all to love presurt\n",
      "thy nother in thew machal fillft enteren, day \n",
      "------ temperature: 1.2\n",
      " love presurt\n",
      "thy nother in thew machal fillft enteren, day apperreve,\n",
      "chatest wyr tall'd his vainill, none retagren\n",
      "obdarks cotpre tortion, through all atitain,\n",
      "our wcomerits, from the prilf,, withl itthern\n",
      "title and notrabtill till\n",
      "nisunalmi'd: and terefent theiraing, with bowe\n",
      "anone shoval refrommy lot\n",
      "iasin,\n",
      "acan reeion, saengst plreace,\n",
      "dessidilt tabe digial isli'n: hop tack for the spirv of tmore\n",
      "actwilled upmiet bokn\n",
      "in griof, not, and his turse fai\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 5 epochs on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=32,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
