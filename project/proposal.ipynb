{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Preliminary Note: Recall that I cannot use any specifically markdown formatting in the notebook, since opening it in PyCharm (a necessary operation to ensure it has saved appropriately) will delete any cell with special markdown formatting.\n",
    "\n",
    "Vision Revision:\n",
    "For my final project, I propose to build a neural network trained to generate poetry in the style of John  Milton. My dataset will be a simple text file containing the entirety of Paradise Lost.\n",
    "\n",
    "Background:\n",
    "This project will use an LSTM (Long short-term memory) trained on the text of Paradise Lost. An LSTM is a specific type of recurrent neural network (RNN) which is structured specifically to be able to learn longer term interdependencies between inputs. This LSTM will analyze the text of Paradise Lost tokenized by letter, and will generate output coorespondingly. My model for this will be Chollet (https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.1-text-generation-with-lstm.ipynb) with some cross-referencing of another example (https://github.com/pranjal52/text_generators) which was unfortunately running too slow to be very useful.\n",
    "\n",
    "Implementation:\n",
    "My implementation is not significantly different from Chollet's at this point. Once it is, I will have more to say on this matter.\n",
    "\n",
    "Results:\n",
    "Again, since my implementation is about the same as Chollet's currently, I do not have final results yet. That being said, these preliminary results are very promising, I think, and there is only room for improvement from here with finetuning Chollet's model.\n",
    "\n",
    "Implications:\n",
    "Poetry is weird. A conglomeration of semi-coherent, half-connected words and phrases whose structure and interplay somehow amount to far more than their mere parts -- it does not seem like the sort of thing that a NN or AI (at least currently) could convincingly fake. It's too human, too subjective. But the fact that it is subjective and often so open to interpretation is exactly what makes the potential for NN-generated poetry so great. If someone doesn't know that a poem has been generated by an un-thinking AI (and no AI that I am aware of can currently be described as thinking, in a human sense), they will impute their own interpretations and understandings into the poem and attribute them to the author. If a NN can generate convingingly human poetry, it is due in large part to how nebulous and varying poetry is in the first place. But that fact is simultaneously why it would be difficult to train a NN to generate convincing poetry. The variation and inconsistency that makes poetry such a uniquely human affair also makes it difficult to train a NN on. This is one of the reasons why I have trouble believing any AI will ever be up to or exceed the capacity of a human beings in their own domains (obviously computers can easily surpass human beings at, say, raw computational power and things of that sort). There is something about us that makes us and our cultural activities distinct from mere mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 454186\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "text = open(\"projectData.txt\").read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 151356\n",
      "Unique characters: 39\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 120\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aqv2/Desktop/cs344-masterfolder/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(128))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "151356/151356 [==============================] - 268s 2ms/step - loss: 2.1437\n",
      "--- Generating with seed: \"resh flourets hill and valley smil'd.\n",
      "this saw his hapless foes, but stood obdur'd,\n",
      "and to rebellious fight rallied thir\"\n",
      "------ temperature: 0.2\n",
      "resh flourets hill and valley smil'd.\n",
      "this saw his hapless foes, but stood obdur'd,\n",
      "and to rebellious fight rallied thir sead to serve to the seate and the seast the serve the seemest the serve to seem the seeps to seeps to perve such to seers, and and to the serve to the fore the serve seep\n",
      "to seem to neent with to with the serpent and the serve to her seeps and all the seeps to seep and the serve to when the serve of the seace to he wores and so serve the frough to the seard and to the serve serve the serve with \n",
      "------ temperature: 0.5\n",
      "e to when the serve of the seace to he wores and so serve the frough to the seard and to the serve serve the serve with earth now levers searse sof reeuse.\n",
      " to seat to deer, and to soeds, and me to the such all in the solent how wead, but now in her secerve to whend, and by found whom seek\n",
      "to for be one, to such and me son under stould of the seam by with from gread of by the sead to deeunds, and with and stround in the ournest in me a reserv'd and sangt, and as the fall'd.\n",
      "\n",
      "so seated the graines, and to serpe to p\n",
      "------ temperature: 1.0\n",
      "with and stround in the ournest in me a reserv'd and sangt, and as the fall'd.\n",
      "\n",
      "so seated the graines, and to serpe to ploudie relauth, dread and reeve mound from most;\n",
      "and arvaine\n",
      "and liin'd they crest\n",
      "sung\n",
      "hendie heic'dd me dewyen,\n",
      "abseltal wark, that with rowemine liss of of my; son sun foold pray she high wall'des, by grade\n",
      "at to he but wape and ittoll,\n",
      "what the fuet\n",
      "os comeowkre i of imhot'd, and and dark'ny hadeal:, at none, wheress reirth and low;\n",
      "nor scaud,\n",
      "toue they sochec,\n",
      "and sicout, to thoughts havors m\n",
      "------ temperature: 1.2\n",
      " and and dark'ny hadeal:, at none, wheress reirth and low;\n",
      "nor scaud,\n",
      "toue they sochec,\n",
      "and sicout, to thoughts havors morn,\n",
      "and forlame, be me,\n",
      "and ovess; ifhich\n",
      "he he, and isarul, wo retrew\n",
      "or to seven, shape depuren, arry frumidg'd, dound\n",
      "our buthedgnee, and toe, in shae trlame, man'd\n",
      "and tospresd,\n",
      "hawed so nour gost of is cring tore by sgreeols of hark of aw werebpite mararous lay\n",
      "orfiv'ck how\n",
      "pelt-wanms with deaded by stasbous'denceain\n",
      "the prandel; thuman,\n",
      "and yout, bould theervere seess,\n",
      "to to mists the stown\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 5 epochs on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
